\documentclass[11pt,a4paper]{article}
\usepackage[hyperref]{acl2020}
\usepackage{times}
\usepackage{latexsym}
\renewcommand{\UrlFont}{\ttfamily\small}
\usepackage{microtype}
\usepackage[autostyle=false, style=english]{csquotes}
\MakeOuterQuote{"}

\aclfinalcopy % Uncomment this line for the final submission
%\def\aclpaperid{***} %  Enter the acl Paper ID here

\newcommand\BibTeX{B\textsc{ib}\TeX}

\title{Laughter Through the Decades: Replicating Humor Detection Research}

\author{Joshua Hoeflich \\
  Northwestern University / 1881 Oak Avenue, Evanston IL \\
  \texttt{joshuahoeflich2021@u.northwestern.edu} \\
  }

\date{}

\begin{document}
\maketitle
\begin{abstract}
We attempt to replicate the results of "Making Computers Laugh: Investigations in Automatic Humor Recognition" by applying the techniques within it for classifying humorous and non-humorous texts to publicly available data sets. We compare the performance of three models: A naive Bayes classifier, an SVM classifier, and a decision tree classifier that uses heuristics based on the presence of antonyms, adult slang, and sounds such as rhymes and alliteration within documents. We train and compare these models on a collection of short jokes, Jeopardy questions, news headlines, and Amazon food reviews. We find that despite substantive differences in the datasets and implementations in our work and the original paper, our systems perform comparably well at the same tasks.
\end{abstract}

\section{Introduction}
Few other tasks illustrate the astonishing effectiveness of machine learning as humor recognition. Comedy seems so subjective and points to so many unanswered deep philosophical questions that, at first glance, the notion of teaching a machine to recognize jokes appears absurd. However, in 2005, computational linguists Rada Mihalcea and Carlo Strapparava published a paper titled "Making Computers Laugh: Investigations in Automatic Humor Recognition" showing that Naive Bayes and Support Vector Machine (SVM) classifiers could do a remarkably good job at distingushing one-liners from many other kinds of texts. The strength of their results merits deeper examination.

In this essay, we describe an attempt to replicate the results of "Making Computers Laugh" over 15 years after its original publication. We describe the steps involved with mimicking their processes and the challenges we faced while trying to do so, taking special note of the places where directly using the methods described in the original work proved infeasible. We then evaluate our new results in comparison with the original ones and conclude with a discussion of relevant related works.

\section{Creating Comparable Data Sets}
Replicating the humor detection systems described in the paper first required finding appropriate data to use on the models described in the article. Unfortunately, as of 2021, the exact data sets used in "Making Computers Laugh" are unavailable. The paper describes an elaborate web scraping process used to collect 16000 one-liners, but the links it uses to describe that method no longer point to live websites. The paper also does not link to the "online proverb collection" it uses for examples of non-humorous input data; it does not describe precisely which Reuters headlines or British National Corpus sentences it uses.

Accordingly, our first task involved finding data different but comparable to that used in the article. For positive examples of humor, we used a collection of over 200,000 short jokes; for negative examples, we used a list of 200,000 Jeopardy questions, a list of 1,000,000 news headlines from the Australian Broadcasting Corporation (ABC), and 500,000 reviews taken from Amazon.com about fine foods. All of these datasets came from kaggle, a website with numerous other extensive datasets and machine learning models.

Using short jokes instead of the one liners in the original paper is appropriate because both forms of data work well with classifiers for the same reason. The original authors note: "While longer jokes can have a relatively complex narrative structure, a one-liner must produce the humorous effect `in one shot', with very few words. These characteristics make this type of humor particularly suitable for use in an automatic learning setting" (2005). The short jokes selected for this replication are not necessarily guaranteed to be exactly one sentence long, but their similar length means that our system will likely perform well or badly on them for reasons analagous to those explored in the original paper.

\section{Replicating Humor Recognition}

\section{Experimental Results}

\section{Conclusion}

\end{document}
